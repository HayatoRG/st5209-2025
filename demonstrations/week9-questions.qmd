---
title: "Week 9 Demonstration"
format: html
editor: visual
---

## Set up

```{r}
#| message: FALSE
library(fpp3)
library(tidyverse)
library(slider)
library(gridExtra)
```

## 1. Best linear predictor

Let $X_1,X_2,\ldots,X_n$ be a collection of random variables. For any random variable $Z$, let $Q[Z]$ denote its best linear prediction given $X_1,\ldots,X_n$. Show that $Q$ is a linear operator, i.e. $Q[\alpha X + \beta Y] = \alpha Q[X] + \beta Q[Y]$ for any random variables $X$ and $Y$, and constants $\alpha,\beta$.

## 2. Recursive forecasting

Fit an AR(2) model on the `gtemp_both` dataset filtered to years prior to 1941. Forecast the mean temperature deviation in 1945 using direct forecasting, and via recursive forecasting, showing that they are the same.

## 3. Nonlinear autoregressive models

Fit a nonlinear AR model using k nearest neighbors on the `globtemp` dataset. Compute its sum of squared residuals and compare it to that of a linear AR model. How about its test error?

## 4. AR(1)

Recall the calculations for AR(1) in Section 11.3 of the notes.

a.  Show directly that the AR(1) forecast is a best linear predictor.

b.  Show that the estimator we introduced was a method of moments estimator.

c.  What is the conditional maximum likelihood estimate for AR(1)?

## 5. AR(2)

Consider the AR(2) equation $$
X_t = 1.5 X_{t-1} - 0.75 X_{t-2} + W_t.
$$

a.  What is the autoregressive polynomial?

b.  What are its roots?

c.  How can we use the roots to compute the period of its ACF? (optional)
